x1<-c(1:1000)*runif(1000,min=0,max=2)
x2<-c(1:1000)*runif(1000,min=0,max=2)
x3<-c(1:1000)*runif(1000,min=0,max=2)
lm_fit<-lm(y~x1+x2+x3)
summary(lm_fit)
set.seed(10)
all_data<-data.frame(y,x1,x2,x3)
View(all_data)
positions <- sample(nrow(all_data),size=floor((nrow(all_data)/4)*3))
training<- all_data[positions,]
testing<- all_data[-positions,]
lm_fit<-lm(y~x1+x2+x3,data=training)
predictions<-predict(lm_fit,newdata=testing)
#error
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(foreach)
length_divisor<-4
iterations<-1000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
error
iterations<-10
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
error
iterations<-100
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
iterations<-500
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
iterations<-1000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
#code randomly samples 1/4 of the training set in each iteration,
error
iterations<-10000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
bagging<-function(training,testing,length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
rowMeans(predictions)
}
bagging<-function(training,testing,length_divisor=4,iterations=1000)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
#rowMeans(predictions)
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
return(error)
}
bagging()
bagging(training, testing)
bagging(training, testing, 4, i)
for (i in 1:20) {
bagging(training, testing, 4, i)
}
for (i in 1:20) {
bagging(training, testing, 4, 3)
}
bagging(training, testing, 4, 1:3)
bagging(training, testing, 4, 1:3)
for (i in 1:20) {
bagging(training, testing, 4, i)
}
bagging(training, testing, 4, 3)
for (i in 1:20) {
bagging(training, testing, 4, i)
}
bagging<-function(training,testing,length_divisor,iterations)
{
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
print(iterations)
#rowMeans(predictions)
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
return(error)
}
for (i in 1:20) {
bagging(training, testing, 4, i)
}
for (i in 2:20) {
bagging(training, testing, 4, i)
}
for (i in 2:20) {
print(bagging(training, testing, 4, i))
}
plot()
plot(1)
for (i in 2:20) {
points(bagging(training, testing, 4, i))
}
errors <- numeric()
errors <- numeric()
for (i in 2:20) {
errors <- c(errors, (bagging(training, testing, 4, i)))
}
plot(errors)
plot(errors, type = "l")
errors <- numeric()
for (i in 2:1000) {
errors <- c(errors, (bagging(training, testing, 4, i)))
}
plot(errors)
plot(errors, type = "l")
tail(errors)
min(errors)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
set.seed(10)
y<-c(1:1000)
x1<-c(1:1000)*runif(1000,min=0,max=2)
x2<-(c(1:1000)*runif(1000,min=0,max=2))^2
x3<-log(c(1:1000)*runif(1000,min=0,max=2))
plot(x1)
plot(x2)
plot(x3)
plot(y)
lm_fit<-lm(y~x1+x2+x3)
summary(lm_fit)
plot(lm_fit)
summary(lm_fit)
set.seed(10)
all_data<-data.frame(y,x1,x2,x3)
positions <- sample(nrow(all_data),size=floor((nrow(all_data)/4)*3))
training<- all_data[positions,]
testing<- all_data[-positions,]
lm_fit<-lm(y~x1+x2+x3,data=training)
predictions<-predict(lm_fit,newdata=testing)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(foreach)
length_divisor<-6
iterations<-5000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(randomForest)
rf_fit<-randomForest(y~x1+x2+x3,data=training,ntree=500)
predictions<-predict(rf_fit,newdata=testing)
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
length_divisor<-6
iterations<-5000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
lm_fit<-lm(y~x1+x2+x3,data=training[train_pos,])
predict(lm_fit,newdata=testing)
}
lm_predictions<-rowMeans(predictions)
library(randomForest)
rf_fit<-randomForest(y~x1+x2+x3,data=training,ntree=500)
rf_predictions<-predict(rf_fit,newdata=testing)
predictions<-(lm_predictions+rf_predictions)/2
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
predictions<-(lm_predictions+rf_predictions*9)/10
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(e1071)
svm_fit<-svm(y~x1+x2+x3,data=training)
svm_predictions<-predict(svm_fit,newdata=testing)
error<-sqrt((sum((testing$y-svm_predictions)^2))/nrow(testing))
error
length_divisor<-6
iterations<-5000
predictions<-foreach(m=1:iterations,.combine=cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos<-1:nrow(training) %in% training_positions
svm_fit<-svm(y~x1+x2+x3,data=training[train_pos,])
predict(svm_fit,newdata=testing)
}
svm2_predictions<-rowMeans(predictions)
error<-sqrt((sum((testing$y-svm2_predictions)^2))/nrow(testing))
error
predictions<-(svm_predictions+rf_predictions)/2
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
predictions<-(svm_predictions*2+rf_predictions)/3
error<-sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
library(mlbench)
install.packages("mlbench", "caret", "caretEnsemble")
library(mlbench)
install.packages("mlbench")
library(mlbench)
install.packages("caret")
library(caret)
install.packages("caretEnsemble")
library(caretEnsemble)
data(Ionosphere)
library(mlbench)
library(caret)
library(caretEnsemble)
# Load the dataset
data(Ionosphere)
dataset <- Ionosphere
dataset <- dataset[,-2]
dataset$V1 <- as.numeric(as.character(dataset$V1))
View(dataset)
View(Ionosphere)
head(dataset)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
# C5.0
set.seed(seed)
fit.c50 <- train(Class~., data=dataset, method="C5.0", metric=metric, trControl=control)
set.seed(seed)
fit.gbm <- train(Class~., data=dataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)
fit.gbm <- train(Class~., data=dataset, method="gbm", metric=metric, trControl=control, verbose=FALSE)
boosting_results <- resamples(list(c5.0=fit.c50, gbm=fit.gbm))
summary(boosting_results)
dotplot(boosting_results)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
seed <- 7
metric <- "Accuracy"
set.seed(seed)
fit.treebag <- train(Class~., data=dataset, method="treebag", metric=metric, trControl=control)
fit.treebag <- train(Class~., data=dataset, method="treebag", metric=metric, trControl=control)
set.seed(seed)
fit.rf <- train(Class~., data=dataset, method="rf", metric=metric, trControl=control)
bagging_results <- resamples(list(treebag=fit.treebag, rf=fit.rf))
summary(bagging_results)
dotplot(bagging_results)
control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')
set.seed(seed)
models <- caretList(Class~., data=dataset, trControl=control, methodList=algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
modelCor(results)
splom(results)
results
install.packages("corrplot")
library(corrplot)
corrplot(modelCor(results), method="number", tl.cex=0.5)
stackControl <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
set.seed(seed)
stack.glm <- caretStack(models, method="glm", metric="Accuracy", trControl=stackControl)
print(stack.glm)
set.seed(seed)
stack.rf <- caretStack(models, method="rf", metric="Accuracy", trControl=stackControl)
print(stack.rf)
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE)
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE)
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE, sep = ";", dec = ",")
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE, sep = ";", dec = ",")
View(concrete)
set.seed(10)
positions <- sample(nrow(concrete),size=floor((nrow(concrete)/4)*3))
positions
sample(nrow(df1))
sample(nrow(df1),)
sample(nrow(concrete))
concrete <- concrete[sample(nrow(concrete)),]
set.seed(10)
positions <- sample(nrow(concrete),size=floor((nrow(concrete)/4)*3))
size=floor((nrow(concrete)/4)*3)
size
nrow(concrete)
sample(1030, 772)
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE, sep = ";", dec = ",")
set.seed(10)
positions <- sample(nrow(concrete),size=floor((nrow(concrete)/4)*3))
training<- concrete[positions,]
testing<- concrete[-positions,]
concrete <- read.csv("D:/Descargas/concrete.csv", header = TRUE, sep = ";", dec = ",")
#training set test set
set.seed(10)
positions <- sample(nrow(concrete),size=floor((nrow(concrete)/4)*3))
training<- concrete[positions,]
testing<- concrete[-positions,]
lm_fit <- lm(strength ~ .:strength, data = training)
lm_fit
lm_fit <- lm(strength ~ .-strength, data = training)
lm_fit
predictions <- predict(lm_fit, newdata = testing)
error <- sqrt((sum((testing$y-predictions)^2))/nrow(testing))
error
plot(concrete)
testing$y-predictions
predictions <- predict(lm_fit, newdata = testing)
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
library(foreach)
length_divisor <- 6
iterations <- 5000
predictions <- foreach(m = 1:iterations,.combine = cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos <- 1:nrow(training) %in% training_positions
lm_fit <- lm(strength ~ .-strength, data = training[train_pos,])
predict(lm_fit, newdata = testing)
}
predictions <- rowMeans(predictions)
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
plot(testing$strength,predictions)
corr(testing$strength,predictions)
cor(testing$strength,predictions)
cor(testing$strength,predictions)^2
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
lm_fit <- lm(strength ~ .-strength, data = training)
predictions <- predict(lm_fit, newdata = testing)
plot(testing$strength,predictions)
cor(testing$strength,predictions)^2
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
length_divisor <- 6
iterations <- 1000
predictions <- foreach(m = 1:iterations,.combine = cbind) %do% {
training_positions <- sample(nrow(training), size=floor((nrow(training)/length_divisor)))
train_pos <- 1:nrow(training) %in% training_positions
lm_fit <- lm(strength ~ .-strength, data = training[train_pos,])
predict(lm_fit, newdata = testing)
}
predictions <- rowMeans(predictions)
plot(testing$strength,predictions)
cor(testing$strength,predictions)^2
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
plot(testing$strength,predictions)
cor(testing$strength,predictions)^2
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
library(randomForest)
rf_fit <- randomForest(strength ~ .-strength, data = training, ntree = 500)
predictions <- predict(rf_fit, newdata = testing)
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
plot(testing$strength,predictions)
cor(testing$strength,predictions)^2
length_divisor <- 6
iterations <- 1000
predictions <- foreach(m = 1:iterations,.combine = cbind) %do% {
training_positions <- sample(nrow(training), size = floor((nrow(training)/length_divisor)))
train_pos <- 1:nrow(training) %in% training_positions
lm_fit <- lm(strength ~ .-strength, data=training[train_pos,])
predict(lm_fit, newdata = testing)
}
lm_predictions<-rowMeans(predictions)
library(randomForest)
rf_fit <- randomForest(strength ~ .-strength, data = training, ntree = 500)
rf_predictions <- predict(rf_fit, newdata = testing)
predictions <- (lm_predictions+rf_predictions)/2
plot(testing$strength, predictions)
cor(testing$strength, predictions)^2
error<-sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
predictions <- (lm_predictions + rf_predictions*9)/10
plot(testing$strength, predictions)
cor(testing$strength, predictions))^2
cor(testing$strength, predictions)^2
error <- sqrt((sum((testing$strength-predictions)^2))/nrow(testing))
error
library(e1071)
svm_fit <- svm(strength ~ .-strength, data = training)
svm_predictions <- predict(svm_fit, newdata = testing)
plot(testing$strength, svm_predictions)
cor(testing$strength, svm_predictions)^2
error<-sqrt((sum((testing$strength - svm_predictions)^2))/nrow(testing))
error
predictions <- (svm_predictions+rf_predictions)/2
plot(testing$strength, predictions)
cor(testing$strength, predictions)^2
error <- sqrt((sum((testing$strength - predictions)^2))/nrow(testing))
error
library(caret)
library(caretEnsemble)
control <- trainControl(method="repeatedcv", number=10, repeats=3, savePredictions=TRUE, classProbs=TRUE)
algorithmList <- c('lda', 'rpart', 'glm', 'knn', 'svmRadial')
set.seed(seed)
dataset <- Ionosphere
data(Ionosphere)
dataset <- Ionosphere
View(dataset)
models <- caretList(strength ~ ., data = dataset, trControl = control, methodList = algorithmList)
models <- caretList(strength ~ ., data = concrete, trControl = control, methodList = algorithmList)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
?caret
algorithmList <- c('M5')
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = TRUE, classProbs=TRUE)
algorithmList <- c('M5')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
algorithmList <- c('lm')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3, savePredictions = TRUE)
algorithmList <- c('lm')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
control <- trainControl(method = "repeatedcv", number = 10, repeats = 3)
algorithmList <- c('lm')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
algorithmList <- c('svmLinear')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
?trainControl
control <- trainControl(method = "cv", number = 10, repeats = 3)
algorithmList <- c('svmLinear')
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
results <- resamples(models)
algorithmList <- c('svmLinear', 'lm')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
algorithmList <- c('svmLinear', 'lm', 'mlp')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
algorithmList <- c('svmLinear', 'lm', 'mlp', 'neuralnet')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, trControl = control, methodList = algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
?trainControl
algorithmList <- c('svmLinear', 'lm', 'mlp', 'neuralnet')
seed <- 7
set.seed(seed)
models <- caretList(strength ~ .-strength, data = concrete, methodList = algorithmList)
results <- resamples(models)
summary(results)
dotplot(results)
?resamples
results <- models
summary(results)
dotplot(results)
cor(results)
models$svmLinear$results
models$lm$results
models$mlp$results
models$neuralnet$results
